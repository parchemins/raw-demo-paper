
\section{Introduction}

Sampling-based approximate query processing (S-AQP)
~\cite{DBLP:conf/sigmod/AgarwalMKTJMMS14} drastically reduce query
execution time to deliver approximated results with error
estimation. S-AQP has many important use-cases in RDF including
computing large scale
statistics\cite{soulet2019anytime,10.1007/978-3-319-18818-8_14},
computing embeddings with random walks\cite{ristoski2016rdf2vec}, join
orderings\cite{DBLP:conf/cidr/LeisRGK017}, approximated
aggregations~\cite{DBLP:journals/tods/LiWYZ19}, summaries
computation~\cite{10.1007/978-3-030-49461-2_10}, exploratory
queries~\cite{DBLP:conf/sigmod/AgarwalMKTJMMS14}.  However, given a
query, current SPARQL endpoints have no support to deliver efficiently
results drawn uniformly at random. To illustrate, to compute large
scale statistics, ~\cite{soulet2019anytime} relies on the following
very simple sampling query $Q_s$:
%
\verb+select * {?s ?p ?o} LIMIT 1 OFFSET r+
%
where $r$ is a random number between 0 and the cardinality of the
served graph. On Wikidata, $0<r<12B$, and unfortunately when $r>100M$,
$Q_s$ time-out on Wikidata returning no result\footnote{other methods
  to sample relying on ORDER BY rand() or SAMPLE with subqueries also
  time-out}. Some SPARQL endpoints providers provides ad-hoc solutions
to compute more efficiently random triples from triple
patterns\footnote{\url{https://docs.stardog.com/query-stardog/sampling-service\#sampling-service.}},
b,
~\footnote{\url{https://docs.openlinksw.com/virtuoso/rndsalltr/}}. However,
the complexity of sampling remains unclear and the sampling is limited
to triple pattern, there is nothing equivalent to the TABLESAMPLE
clause that is part of the SQL standard since 2003.

% From the state of art~\cite{DBLP:conf/cidr/LeisRGK017}, we know that
% is possible to draw a random triple from a triple pattern in
% logarithmic time using the internal index of a TripleStore. Extending
% to BGP support just multiply this complexity by the number of triple
% pattern in the query. Sampling queries makes sense only if the
% approximation error can also be estimated ie. for a query

In this demonstration, we extended JENA to support efficiently
sampling-based approximate query processing for core SPARQL queries.
Given a core SPARQL $Q$ query and a budget in time,
\NAME~\footnote{\url{https://github.com/Chat-Wane/raw-jena}} is
able to deliver random results along with a cardinality estimation of
the total number of results. The complexity of the sampling is in
$O(k.log(|D|)$ where $k$ is the number of triple pattern in
$Q$. \NAME supports the pay-as-you-approach ie. sampling the query
multiple times returns more result and improve the accuracy of the
cardinality.
%
In the demonstration, we show that for a query that time-out on
wikidata (60s) and deliver partial non-random results, we deliver in
1s partial random results along with an accurate cardinality
estimation of the query. This correspond to the exploratory query
use-case, but the others use-cases are also possible using the same
the API.






% \section{Introduction (from quota)}

% Public SPARQL endpoints as Wikidata or DBPedia allow anyone to execute
% any SPARQL queries. However, due to fair use policies of public SPARQL
% endpoints, there is no guarantee of termination with complete
% results. On Wikidata, queries are stopped after 60s returning partial
% results~\footnote{\url{https://www.mediawiki.org/wiki/Wikidata_Query_Service/User_Manual}},
% On Dbpedia, the maximum execution time is set to 120 second with a
% maximum 10000
% results~\footnote{\url{https://www.dbpedia.org/resources/sparql/\#ratesandlimits}}. Consequently,
% it exist a class of SPARQL queries that time-out when executed on
% public SPARQL endpoint~\cite{DBLP:conf/semweb/MalyshevKGGB18} that is
% the base for the Wikidata benchmark\cite{angles2022wdbench}.

% It is impossible for a SPARQL endpoint to ensure that any query
% returns complete results in fixed time. However, it is possible to
% ensure to return a sample of results in fixed time, along with an
% estimation of the cardinalities of complete results. For example, the
% $Q_1$ of figure~\ref{fig:q1-nojo} timeout on Wikidata, returning
% partial non-random results. However, it is possible to sample the
% evaluation of Q1, returning random results along with an estimation of
% the cardinality of results with a confidence interval. For a budget of
% 1s, on JENA-RAW, we obtained 50 results on potentially 1000 results
% more or less 50.

% Sampled results can be incrementally improved following a
% pay-as-go approach ie. resending the same
% query for another budget of 1s allows to get other random results with
% possible duplicates, but with an higher accuracy on cardinality.



% \begin{figure}[t]
%  \begin{center}
%   \subfloat [Query $Q_1^{J_1}$ time-out >60s] {\label{fig:q1-nojo}
%    \adjustbox{valign=T}{
%     \resizebox{0.45\textwidth}{!}{
%      \lstinputlisting[basicstyle=\scriptsize\sffamily,
%      language=sparql,numbers=none,columns=fixed,
%      showstringspaces=false]{./figures/q1w.rq}}}}
%   \subfloat [Query $Q_1^{J_2}$ forced join order $\sim 451ms$] {\label{fig:q1j2}
%    \adjustbox{valign=T}{
%     \resizebox{0.45\textwidth}{!}{
%      \lstinputlisting[basicstyle=\scriptsize\sffamily,
%      language=sparql,numbers=none,columns=fixed,
%      showstringspaces=false]{./figures/q1w-jo.rq}}}}
%  \end{center}
%  \caption{The query $Q_1$ searches for creative works and the list of
%   fiction works that inspired them. $Q_1$ time-out on
%   the Wikidata online server (>60s)}
%  \label{fig:q1}
% \end{figure}

% Sampling query evaluation has many practical use-cases that is
% currently limited as computing
% large scale statistics\cite{soulet2019anytime}, embeddings with random
% walks\cite{ristoski2016rdf2vec}, join
% orderings\cite{DBLP:conf/cidr/LeisRGK017}, approximated
% aggregations\cite{DBLP:journals/tods/LiWYZ19}.




% To validate our
% approach, we extended JENA with a sampling interface and show what can
% be obtained with fixed time for queries that traditionaly time-out on
% public endpoints.




% Random walks are important but do not have efficient implementations,
% or unsufficient API. More importantly, they are precluded to servers
% and they do not let outsiders use them.

% Could go for triple/quad patterns and it would be enough. But the more
% we push to server the more efficient.

% Especially relevant for SPARQL since we often have all indexes.

% We limit ourself to a subset of SPARQL for now. We do not process
% property paths although it would be possible. Optionals, set minus, are
% difficult.

% \todo{MUST shoot a short video to showcase \NAME. And link it.}

% Random walks enable few use-cases (from most easy to most demanding)
% such as:
% \begin{asparadesc}
% \item [Summaries] needs random walk values.
% \item [pyRDF2Vec~\cite{steenwinckel2023pyrdf2vec}] needs random walk values.
% \item [FedUP] needs the graphs of random walks.
% \item [Join ordering~\REF] needs cardinalities of random walks.
% \item [Sparklis~\cite{ferre2017sparklis}] needs random walks (at
%   least) and cardinality (optional).
% \item [Wander Join~\cite{li2016wanderjoin}] needs the cardinality of
%   random walks, failed and succeeded.
% \end{asparadesc}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper.tex"
%%% End:
